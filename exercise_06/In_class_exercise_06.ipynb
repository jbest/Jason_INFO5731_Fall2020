{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_06.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/In_class_exercise/In_class_exercise_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7TahL04sVvR"
      },
      "source": [
        "# **The sixth in-class-exercise (20 points in total, 3/2/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyZITr8sjnh"
      },
      "source": [
        "## **1. Rule-based information extraction (10 points)**\n",
        "\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the **titles** of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvR_O9D8sOUY",
        "outputId": "ccaf48a2-63a5-41e9-aec6-a4781d026357"
      },
      "source": [
        "# Write your code here\n",
        "!pip install scholarly"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scholarly\n",
            "  Downloading https://files.pythonhosted.org/packages/27/e9/04ac316394fe8a54c982f9071aab6075723aa459a0ce95a48baeb8a23a0d/scholarly-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: PySocks in /usr/local/lib/python3.7/dist-packages (from scholarly) (1.7.1)\n",
            "Collecting python-dotenv\n",
            "  Downloading https://files.pythonhosted.org/packages/32/2e/e4585559237787966aad0f8fd0fc31df1c4c9eb0e62de458c5b6cde954eb/python_dotenv-0.15.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from scholarly) (4.6.3)\n",
            "Collecting stem\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/bd/ab05ffcbfe74dca704e860312e00c53ef690b1ddcb23be7a4d9ea4f40260/stem-1.8.0.tar.gz (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 13.7MB/s \n",
            "\u001b[?25hCollecting free-proxy\n",
            "  Downloading https://files.pythonhosted.org/packages/04/e0/73bc201cfabca899daa033aeeeed37d30412fbd6c4877585a406f3a0fa99/free_proxy-1.0.2-py3-none-any.whl\n",
            "Collecting arrow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/14/eb71fc7e91384f2890405aca8b4b23e1adb725cb68beb456ae5898a99ac8/arrow-1.0.2-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hCollecting fake-useragent\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/79/af647635d6968e2deb57a208d309f6069d31cb138066d7e821e575112a80/fake-useragent-0.1.11.tar.gz\n",
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests[security] in /usr/local/lib/python3.7/dist-packages (from scholarly) (2.24.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from scholarly) (3.7.4.3)\n",
            "Collecting bibtexparser\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/c3/c184a4460ba2f4877e3389e2d63479f642d0d3bdffeeffee0723d3b0156d/bibtexparser-1.2.0.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hCollecting sphinx-rtd-theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/81/d5af3a50a45ee4311ac2dac5b599d69f68388401c7a4ca902e0e450a9f94/sphinx_rtd_theme-0.5.1-py2.py3-none-any.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from free-proxy->scholarly) (4.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from arrow->scholarly) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium->scholarly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[security]->scholarly) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[security]->scholarly) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[security]->scholarly) (2020.12.5)\n",
            "Collecting cryptography>=1.3.4; extra == \"security\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/1f/acde6ff69864c5e78b56488e3afd93c1ccc8c2651186e2a5f93d93f64859/cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 49.6MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=0.14; extra == \"security\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/5e/06351ede29fd4899782ad335c2e02f1f862a887c20a3541f17c3fa1a3525/pyOpenSSL-20.0.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from bibtexparser->scholarly) (2.4.7)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from bibtexparser->scholarly) (0.16.0)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from sphinx-rtd-theme->scholarly) (1.8.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.0->arrow->scholarly) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4; extra == \"security\"->requests[security]->scholarly) (1.14.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (20.9)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (1.2.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (2.1.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (2.9.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (0.7.12)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (0.16)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (2.11.3)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (1.2.4)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (2.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx->sphinx-rtd-theme->scholarly) (54.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4; extra == \"security\"->requests[security]->scholarly) (2.20)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->sphinx->sphinx-rtd-theme->scholarly) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx->sphinx-rtd-theme->scholarly) (1.1.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->sphinx-rtd-theme->scholarly) (1.1.4)\n",
            "Building wheels for collected packages: stem, fake-useragent, bibtexparser\n",
            "  Building wheel for stem (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stem: filename=stem-1.8.0-cp37-none-any.whl size=436039 sha256=827173971db15aa34cd8a448fc74c60ef711146f9effa815ff231b45d2d482ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/3a/ee/1094b166e029353f892c0b121aa02f48aff5e658396924bc2a\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-cp37-none-any.whl size=13485 sha256=f5c8734ce48030f101ea4df723cabea10ee0786413d57a153100162f86be39cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/63/09/d1dc15179f175357d3f5c00cbffbac37f9e8690d80545143ff\n",
            "  Building wheel for bibtexparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bibtexparser: filename=bibtexparser-1.2.0-cp37-none-any.whl size=36712 sha256=ca03d1fb5fbb221b4964550a0c55e62cd9465a5157990d0e2b6a3d64839f0645\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/5a/e7/867bcbc3a81c15b675b931aa19b6698375c5a5e90419a366db\n",
            "Successfully built stem fake-useragent bibtexparser\n",
            "Installing collected packages: python-dotenv, stem, free-proxy, arrow, fake-useragent, selenium, bibtexparser, sphinx-rtd-theme, scholarly, cryptography, pyOpenSSL\n",
            "Successfully installed arrow-1.0.2 bibtexparser-1.2.0 cryptography-3.4.6 fake-useragent-0.1.11 free-proxy-1.0.2 pyOpenSSL-20.0.1 python-dotenv-0.15.0 scholarly-1.1.0 selenium-3.141.0 sphinx-rtd-theme-0.5.1 stem-1.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceOUqScg11iB"
      },
      "source": [
        "from scholarly import scholarly\n",
        "import csv"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99eu-bnB2QGl"
      },
      "source": [
        "search_query = scholarly.search_pubs('Natural Language Processing herbarium')\n",
        "\n",
        "# Writing to file because Google is sometimes blocking queries\n",
        "file_object = open('google_scholar_results.jsonl', 'w')\n",
        "\n",
        "for i in range(100):\n",
        "    #file_object.write(str(i))\n",
        "    file_object.write(str(next(search_query)))\n",
        "    file_object.write('\\n')\n",
        "file_object.close()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "NEn8iL-VrcBL",
        "outputId": "71dcc53c-43dd-40fa-8bd0-f1cdf9ede57b"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('google_scholar_results.jsonl', 'r') as result_data:\n",
        "  #reader = csv.DictReader(result_data)\n",
        "  data = result_data.readlines()\n",
        "  for row in data:\n",
        "    #print(row)\n",
        "    json_data = json.loads(row.replace(\"\\'\", \"\\\"\"))\n",
        "    print(json_data)\n",
        "\n",
        "#print(data)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'title': 'Towards a scientific workflow featuring Natural Language Processing for the digitisation of natural history collections', 'author': ['D Owen', 'L Livermore', 'Q Groom', 'A Hardisty'], 'pub_year': '2020', 'venue': 'Research Ideas and …', 'abstract': 'Optical Character Recognition (OCR) and Natural Language Processing (NLP) are two technologies that may support the  conversion of that text to a format that may be processed by machine  Herbarium specimens are among the most difficult targets and we know from recent'}\n",
            "{'title': 'Going deeper in the automated identification of Herbarium specimens', 'author': ['J Carranza-Rojas', 'H Goeau'], 'pub_year': '2017', 'venue': 'BMC …', 'abstract': 'The estimated number of specimens in Natural History collection is in the 2–3 billion range [2  present in this type of image is very high for fully automated computer vision processing  initiatives such as iDigBio already provide access to more than 14 million herbarium images [9'}\n",
            "{'title': 'The largest digital herbarium in Russia is now available online!', 'author': ['AP Seregin'], 'pub_year': '2018', 'venue': 'Taxon', 'abstract': 'The Moscow University Herbarium (MW) is the second-largest herbarium in Russia after the Komarov Institute in St. Petersburg. As of January 2018, it holds 1 030 669 specimens of vascular plants and bryophytes. New technical staff were recently employed to facilitate further growth'}\n",
            "{'title': 'The SALIX Method: A semi‐automated workflow for herbarium specimen digitization', 'author': ['A Barber', 'D Lafferty', 'LR Landrum'], 'pub_year': '2013', 'venue': 'Taxon', 'abstract': 'The images are renamed, archived, and post-processed in the same way as the full specimen images  to be moderately faster than typing, but more impor- tantly, it has opened up new possibilities in natural language processing and the digitization of herbarium specimens'}\n",
            "{'title': 'A benchmark dataset of herbarium specimen images with label data', 'author': ['M Dillen', 'Q Groom', 'S Chagnoux', 'A Güntsch'], 'pub_year': '2019', 'venue': 'Biodiversity data …', 'abstract': 'Finnish Museum of Natural History LUOMUS, University of Helsinki, H, FinBIF, As Table 1; 14 FI, 36 ET  No further image processing of JPEG or TIFF files was done  These data were subsequently mapped to DwC in the R language using the package jsonlite (Ooms 2014 and'}\n",
            "{'title': 'High‐performance digitization of natural history collections: automated imaging lines for herbarium and insect specimens', 'author': ['R Tegelberg', 'T Mononen', 'H Saarenmaa'], 'pub_year': '2014', 'venue': 'Taxon', 'abstract': 'namespace is being uniquely maintained by the Finnish Museum of Natural History (http  operating system and the camera interface software (pyHTTPDSLR, written using Python programming language)  imaging of the speci- men and ID were notified during post-processing'}\n",
            "{'title': 'Taxon and trait recognition from digitized herbarium specimens using deep convolutional neural networks', 'author': ['S Younis', 'C Weiland', 'R Hoehndorf', 'S Dressler'], 'pub_year': '2018', 'venue': 'Botany …', 'abstract': 'The application of deep learning on natural history collections is a very recent development  and faster computers allowing also larger image sizes to be processed and thereby to  Biodiversity and Climate Research Center with focus on deep learning and image processing'}\n",
            "{'title': 'Herbarium survey of african Corchorus L. species.', 'author': ['JM Edmonds'], 'pub_year': '1990', 'venue': 'NA', 'abstract': 'This publication is the result of a joint IBPGR-International Jute Organization (IJO) initiative to examine specimens of Corchorus species in recognized herbaria in Europe and East Africa and to produce technical reports on the geographic distribution, habitats, fruiting patterns and'}\n",
            "{'title': 'LeafMachine: Using machine learning to automate leaf trait extraction from digitized herbarium specimens', 'author': ['WN Weaver', 'J Ng', 'RG Laport'], 'pub_year': '2020', 'venue': 'Applications in plant sciences', 'abstract': 'ability to correctly identify single leaves, we ran the software on herbarium specimen images  pixels, high = 3744 × 5616 pixels), resulting in a total of 21,316 processed images  required 631 compute hours across a variety of computational resources (image processing times for'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-81d7cd82dc2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#print(row)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 335 (char 334)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giABEnnLPyXg",
        "outputId": "6ddfc52c-f601-45b7-e84a-73370d70e027"
      },
      "source": [
        "import json\n",
        "import string\n",
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "#nltk('punkt.download')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "author_count = {}\n",
        "titles = []\n",
        "abstracts = []\n",
        "#titles_abstracts = []\n",
        "with open('google_scholar_results.jsonl', 'r') as result_data:\n",
        "    data_string = result_data.readlines()\n",
        "    for row in data_string:\n",
        "        #json_data = json.loads(row.replace(\"\\'\", \"\\\"\"))\n",
        "        data = json.loads(str(row))\n",
        "        title = data['title']\n",
        "        titles.append(title)\n",
        "        abstract = data['abstract']\n",
        "        abstracts.append(abstract)\n",
        "        for author in data['author']:\n",
        "            #print(author)\n",
        "            a_count = author_count.get(author, 0)\n",
        "            a_count += 1\n",
        "            author_count[author] = a_count\n",
        "\n",
        "print(author_count)\n",
        "#print(titles)\n",
        "titles_string = ' '.join(titles)\n",
        "#print(titles_string)\n",
        "\n",
        "# Tokenize titles\n",
        "titles_tokenized = []\n",
        "for title in titles:\n",
        "    toked = word_tokenize(title)\n",
        "    titles_tokenized.append(toked)\n",
        "#print(titles_tokenized)\n",
        "\n",
        "#Lower casing\n",
        "lowered = []\n",
        "for sent in titles_tokenized:\n",
        "    words = [word.lower() for word in sent]\n",
        "    lowered.append(words)\n",
        "#print('Lowercase:', lowered)\n",
        "\n",
        "#Punctuation removal\n",
        "# make translation for punctuation\n",
        "remove_punctuation = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "#text = text.translate(remove_punctuation)\n",
        "no_punc = []\n",
        "for sent in lowered:\n",
        "    no_punc_sent = []\n",
        "    for word in sent:\n",
        "        no_punc_sent.append(word.translate(remove_punctuation))\n",
        "    no_punc.append(no_punc_sent)\n",
        "#print('No punctuation:', no_punc)\n",
        "\n",
        "#Stopwords removal\n",
        "# Load NLTK stopwords\n",
        "stop = stopwords.words('english')\n",
        "no_stops = []\n",
        "for sent in no_punc:\n",
        "    no_stop_sent = []\n",
        "    for word in sent:\n",
        "        if word not in stop:\n",
        "            # remove blanks and whitespace\n",
        "            if len(word.strip())>0:\n",
        "                no_stop_sent.append(word)\n",
        "    no_stops.append(no_stop_sent)\n",
        "#print('Stopwords removed:', no_stops)\n",
        "\n",
        "#Stemming\n",
        "st = PorterStemmer()\n",
        "titles_stemmed = []\n",
        "for sent in no_stops:\n",
        "  new_sent = []\n",
        "  for word in sent:\n",
        "    new_sent.append(st.stem(word))\n",
        "  titles_stemmed.append(new_sent)\n",
        "#print('Stemmed:', titles_stemmed)\n",
        "\n",
        "\"\"\"\n",
        "#1.2 - Lemmatization\n",
        "from textblob import Word\n",
        "\n",
        "titles_lemmed = []\n",
        "for sent in no_stops:\n",
        "  new_sent = []\n",
        "  for word in sent:\n",
        "    new_sent.append(st.stem(Word(word).lemmatize()))\n",
        "  titles_lemmed.append(new_sent)\n",
        "print('Lemmatized:', titles_lemmed)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#tokens = nltk.word_tokenize(titles_string)\n",
        "all_titles = [item for sublist in titles_stemmed for item in sublist]\n",
        "\n",
        "fdist=FreqDist(all_titles)\n",
        "word_frequency = []\n",
        "for key in fdist:\n",
        "    #print(key, fdist[key])\n",
        "    word_frequency.append((key, fdist[key]))\n",
        "\n",
        "top_words = word_frequency[:10]\n",
        "print(top_words)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'D Owen': 1, 'L Livermore': 1, 'Q Groom': 2, 'A Hardisty': 1, 'J Carranza-Rojas': 1, 'H Goeau': 1, 'AP Seregin': 3, 'A Barber': 1, 'D Lafferty': 1, 'LR Landrum': 1, 'M Dillen': 1, 'S Chagnoux': 1, 'A Güntsch': 1, 'R Tegelberg': 1, 'T Mononen': 1, 'H Saarenmaa': 1, 'S Younis': 1, 'C Weiland': 1, 'R Hoehndorf': 1, 'S Dressler': 1, 'JM Edmonds': 1, 'WN Weaver': 1, 'J Ng': 1, 'RG Laport': 1, 'RWG Dennis': 1, 'BM Thiers': 1, 'MC Tulig': 1, 'KA Watson': 1, 'PK Holmgren': 1, 'W Keuken': 1, 'DA Metsger': 1, 'SC Byers': 1, 'DJ Cantrill': 1, 'VC Bieker': 1, 'MD Martin': 1, 'E Nic Lughadha': 1, 'BE Walker': 1, 'JM Heberling': 1, 'LA Prather': 1, 'SJ Tonsor': 1, 'G Le Bras': 1, 'M Pignal': 2, 'ML Jeanson': 1, 'S Muller': 1, 'C Aupic': 1, 'MV Kozlov': 1, 'IV Sokolova': 1, 'V Zverev': 1, 'AA Egorov': 1, 'L Fish': 1, 'E Anderson': 1, 'WB Turrill': 1, 'Í Granzow-de la Cerda': 1, 'JH Beach': 2, 'CX Zeng': 2, 'PM Hollingsworth': 1, 'J Yang': 1, 'DA Ledesma': 1, 'CA Powell': 1, 'J Shaw': 1, 'M Nemati Pykani': 1, 'AAS Jafari': 1, 'N Jalilian': 1, 'F Noori': 1, 'E Figueiredo': 1, 'GF Smith': 1, 'V Silva': 1, 'L Dincă': 6, 'R Enescu': 2, 'A Oneț': 1, 'V Laslo': 1, 'SA Mori': 2, 'LAM Silva': 2, 'RB Primack': 1, 'AS Gallinat': 1, 'T van Andel': 1, 'S Veldman': 1, 'P Maas': 1, 'G Thijsse': 1, 'R Beaman': 1, 'B Conn': 1, 'RMS Costa': 1, 'T Van Andel': 1, 'P Pavone': 1, 'Z Barina': 1, 'GE Brewer': 1, 'JJ Clarkson': 1, 'O Maurin': 1, 'AR Zuntini': 1, 'M Marder': 1, 'A Tondeur': 1, 'IC Cântar': 2, 'M Delgado': 1, 'W Fajardo': 1, 'E Gibaja': 1, 'D Vasile': 3, 'A Indreica': 1, 'HA Hyde': 1, 'AE Wade': 1, 'A Takano': 1, 'Y Horiuchi': 1, 'Y Fujimoto': 1, 'K Aoki': 1, 'G Li': 1, 'G Xu': 1, 'K Guo': 1, 'S Du': 1, 'JW Morris': 1, 'SL Mosyakin': 1, 'HJ Esser': 1, 'H Freitag': 1, 'R Lücking': 1, 'R Radji': 1, 'K Adjonou': 1, 'MLA Quashie': 1, 'KE Sodjinou': 1, 'T Fang': 1, 'JB Yang': 1, 'DZ Li': 1, 'G Martínez-Sagarra': 1, 'JA Devesa': 1, 'T Bačič': 1, 'B Trčak': 1, 'N Jogan': 1, 'RW Johnson': 1, 'II Gureyeva': 1, 'Y Zhu': 1, 'T Durand': 1, 'E Chenin': 1, 'BGK Royal': 1, 'A Holland': 1, 'K Vánky': 1, 'C Vánky': 1, 'JA Stevenson': 1, 'JB Cakpenter': 1, 'TH Arnold': 1, 'D Jeanmonod': 1, 'A Charpin': 1, 'GP Martelli': 1, 'G Piro': 1, 'E Vechiu': 1, 'WE Moen': 1, 'J Huang': 1, 'MJ McCotter': 1, 'S Ribeiro': 1, 'F Delgado': 1, 'MD Espírito-Santo': 1, 'CL Campell': 1, 'C Mohr': 1, 'S Zhang': 1, 'H Kanai': 2, 'B Antarctic': 1, 'G Torkar': 1, 'I Mavrič': 1, 'E Miki': 1, 'K Kondo': 1, 'M Okada': 1, 'S Sekita': 1, 'G Consiglio': 1, 'P Franchi': 1, 'M Marchetti': 1, 'M Dincă': 1, 'T Blaga': 1, 'C Botes': 1, 'T van der Niet': 1, 'RM Cowling': 1, 'F Huettmann': 1, 'SM Ickert-Bond': 1, 'EHC McKenzie': 1, \"PJ O'Sullivan\": 1, 'JP Wilkie': 1, 'B Öztürk': 1, 'MA Ege': 1, 'E Esfandiari': 1, 'CV Yaringano': 1, 'RBGS Australia': 1, 'ALL Harmon': 1, 'M Zang': 1, 'G Kniely': 1, 'R McCarty': 1, 'JM Swales': 1, 'N Godwin': 1, 'AV Slavgorodskiy': 1, 'O Jancke': 1, 'L Lange': 1, 'MHO Pinheiro': 1, 'RT Wijewantha': 1, 'P Neebgaabd': 1, 'I Chisăliță': 1, 'C Sérgio': 1, 'C Garcia': 1, 'JA Alejandre': 1, 'J Benito Ayuso': 1, 'S Grayer': 1, 'D Miller': 1, 'H Kauserud': 1, 'AT Bâ': 1, 'JE Madsen': 1, 'B Sambou': 1, 'H Özçelik': 1, 'M Korkmaztürk': 1, 'J Soun': 1, 'N Franz': 1, 'C Gries': 1, 'E Gilbert': 1}\n",
            "[('herbarium', 94), ('collect', 19), ('specimen', 19), ('plant', 19), ('use', 13), ('data', 11), ('speci', 8), ('autom', 7), ('digit', 7), ('imag', 7)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "CSl4fWMzQUNu",
        "outputId": "925e1b16-dd35-493f-8b9f-9ba3f60ad62d"
      },
      "source": [
        "# plot data\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "graph_data = top_words\n",
        "#graph_data = sorted(graph_data) \n",
        "x, y = zip(*graph_data) \n",
        "plt.figure(figsize=(20,5))\n",
        "plt.xlabel(\"Word stem\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Frequency of Words in Article Titles\")\n",
        "plt.bar(x, y)\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIwAAAFNCAYAAABi2vQZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debgkZX0v8O8PRkAEBGVCEJcxQlTcFXE3Kj5e44oGUYOKK9ebxDUaiclN0BgvGnfNY4JLwIh7jKIYNxRcQGRRNhEhLAqCooKKYhR47x/1Huk6njNzZulzzsx8Ps/Tz+mqeqvq111d3T3feevtaq0FAAAAAGZssdQFAAAAALC8CIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAsEmpqttW1Ter6udV9fwlruXpVfWVdVjvv6rqwGnUtBY1nFVVD1pAu1ZVu2/gfR9QVZ9dzfIHVdXFG3KfAMCYwAgANiJVdWFVXV1VV03cbrbUdS0zf5Xki6217Vtrb5lcUFVPrqqzZ8373DzzDl6EWufUWvvj1toR67ONqjq2qq6oqq0X0PbwqnrVrBru0Fo7dn1qWM3+Xj7x+v1VVV07MX1Wa+3I1trDJtpv8FAKAFg9gREAbHwe3VrbbuL2/cmFVbViqQpbJm6V5Kx5ln0pye2qamXy2+fqLkluOGvefXrbBVtOz3tVrUrygCQtyWPW0HbLRShppLX26pnXb5LnJjlh4vV8h8WuBwD4XQIjANgE9B4Yf15V5yY5t897VL8068qqOr6q7jzR/m5VdWq/bOuDVfWBmR4mc11GNdnDo6q2rqrXVdV3q+oHVfUvVXXDvuxBVXVxVf1lVf2wqi6tqmdMbOeGVfX6qrqoqn5aVV/p846uqufN2ufpVfW4eR7vY/olU1f2njS37/O/kOTBSd7We6v84eR6rbVLkpyf5IF91t0zhEvHzZq3RZKTqurGVfWeqrq81/y3VbXFxPP01ap6Y1X9OMkhVXXTqjqqqn5WVV9PcpuJmqu3/WFffkZV3XGex3dsVT178nj05/yKqrqgqv54rvUmPC3J15IcnmR0aVvvTfT2qvpUVf0iybOSHJDkr/pz9one7sKqemi/v2XvFfTf/TVzSlXdYo66531trI3J12BVzQR3p/X6njhH+5tV1X/043RBTVyKWFV7V9XJ/Tn/QVW9YW3rAYDNkcAIADYd+ya5V5I9q+puSd6d5H8nuWmSf01yVP8H/VZJPpbk35PcJMmHk/zJWuzn0CR/mOSuSXZPsluSv5tY/vtJbtznPyvJP1fVTn3Z65LcI8l9+77/Ksl1SY5I8pSZDVTVXfr6R8/eeQ+B3p/khUlWJvlUkk9U1VattYck+XKSv+i9Vb4zR/1fyvXh0AN7+6/Mmve11tpvkry1P5Y/SPJHGYKYZ0xs614ZAqhdkvxjkn9O8qskuyZ5Zr/NeFjf9h/2be6f5Mdz1DeXeyU5J8nOSV6b5F1VVatp/7QkR/bb/6qqXWYt/9Ne7/ZJ3tPbvbY/Z4+eY3svTvLkJI9IskN/XL+co92aXhtrrbU2c1zu0uv74OTyHuB9IslpfX/7JHlhVf2v3uTNSd7cWtshQ4D3ofWpBwA2FwIjANj4fKz3rLmyqj42Mf//tdZ+0lq7OslBSf61tXZia+3aPh7O/yS5d7/dIMmbWmu/aa19JMlJC9lxDykOSvKivq+fJ3l1kidNNPtNklf2bX8qyVVJbtv/Yf/MJC9orV3S6zq+tfY/SY5K8odVtUffxlOTfLC19us5ynhikqNba5/roc7rktwwQwi1EJO9iR6QITD68qx5x9VwqdaTkvx1a+3nrbULk7y+1zbj+621t7bWrkny6wzB29+11n7RWjszQxA2+bxsn+R2Saq1dnZr7dIF1nxRa+0drbVr+zZ3zRBS/Y6qun+Gy/I+1Fo7Jcl/ZwiIJn28tfbV1tp1rbVfLWD/z07yt621c9rgtNbaKOxa4GtjGu6ZZGVr7ZWttV+31s5P8o6J/f4mye5VtXNr7arW2temXA8AbBIERgCw8dm3tbZjv+07Mf97E/dvleQvJ4KlK5PcIsnN+u2S1lqbaH/RAve9Msm2SU6Z2O6n+/wZP+4ByoxfJtkuQ++YbTIEGCM9tPhgkqf0YOnJGXpAzeVmk/W21q7L8Nh3W+Bj+FKSO/deT/fOMH7Ot5Ps2ufdv7fZOUOwNvncXDRrP5PP+cokK2bNm6zzC0nelqEX0g+r6rCq2mGBNV82sZ2Znj3bzdP2wCSfba39qE+/L7MuS5tV40LcInMct1kW8tqYhlsludms1/rLc32g9qwMvZ6+XVUnVdWjplwPAGwSBEYAsOmYDIC+l+QfJ4KlHVtr27bW3p/k0iS7zbqk6ZYT93+R4R/+SZKq+v2JZT9KcnWSO0xs98Z98OI1+VGGy7VuM8/yIzKMpbNPkl+21k6Yp933M4QEM/VVhkDjkgXUkN4D5fsZesN8t7V2VV90Qp+3XYbxf36UoXfKrSZWv+Ws/Uw+55cnuabXMtl+ct9vaa3dI8meGUKMly6k5oXq4wXtn+SPquqyqrosyYuS3KVf5jdX3XNNz/a9zH/cZqzPa2N9fC/JBbNe69u31h6RJK21c1trT07ye0lek+QjVXWjKdcEABs9gREAbJrekeS5VXWvPtjyjarqkVW1fYZg5Jokz6+qG1TV45PsPbHuaUnuUFV3raptkhwys6D35nlHkjdW1e8lSVXtNjFezLz6uu9O8oY+SPGWVXWf6j/73gOi6zJc9jVf76JkGIPmkVW1T1XdIMlfZrjc7vgFPTODL2cYl+fLE/O+0ued3Fq7ul/+9aEk/1hV21fVrfry987z+K5N8tEMg19vW1V7ZqJnT1Xdsx+PG2QI5X7VH++GtG+SazMEUnftt9v3x/m01az3gwzjNM3nnUn+oar26K+nO1fVTScbrM9rYwFWV9/Xk/y8ql5WwwDqW1bVHavqnr2Gp1TVyl7flX2dDf28A8AmR2AEAJug1trJSZ6T4RKoK5Kcl+Tpfdmvkzy+T/8kw5hAH51Y9ztJXpnk8xl+cW30i2lJXta397Wq+llvd9sFlvaSJGdkGDPpJxl6fEx+H3lPkjtlnlCm13dOhgGy35qhV8ujkzx6nvGO5nNchh4nk4/ty33elybmPS9DuHN+b/u+DKHXfP4iQw+lyzL8Qtm/TSzbIUOgckWGS9V+nOSf1qLmhTgwyb+11r7bWrts5pbhdXBAVa2YZ713ZRgsffa4WDPekCE8+2ySn/X2c/362fq8NlbnkCRH9Pr2n1zQg7pHZQjHLsjwmnhnhoHFk+ThSc6qqqsyDID9pD7OFwCwGjUevgAA2BxV1eFJLm6t/e0S1/G0JAe11u6/lHUAAGzu9DACAJaFqto2yZ8lOWypawEA2NwJjACAJdfHubk8w1g171vicgAANnsuSQMAAABgRA8jAAAAAEYERgAAAACMzPfTqsvKzjvv3FatWrXUZQAAAABsMk455ZQftdZWzrVsowiMVq1alZNPPnmpywAAAADYZFTVRfMtc0kaAAAAACMCIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwIjACAAAAYERgBAAAAMCIwAgAAACAEYERAAAAACMCIwAAAABGBEYAAAAAjKxY6gI2N6sOPnqpS9gkXHjoI5e6BAAAANhk6WEEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAICRqQZGVfWiqjqrqs6sqvdX1TZVdeuqOrGqzquqD1bVVtOsAQAAAIC1M7XAqKp2S/L8JHu11u6YZMskT0rymiRvbK3tnuSKJM+aVg0AAAAArL1pX5K2IskNq2pFkm2TXJrkIUk+0pcfkWTfKdcAAAAAwFqYWmDUWrskyeuSfDdDUPTTJKckubK1dk1vdnGS3eZav6oOqqqTq+rkyy+/fFplAgAAADDLNC9J2ynJY5PcOsnNktwoycMXun5r7bDW2l6ttb1Wrlw5pSoBAAAAmG2al6Q9NMkFrbXLW2u/SfLRJPdLsmO/RC1Jbp7kkinWAAAAAMBammZg9N0k966qbauqkuyT5FtJvphkv97mwCQfn2INAAAAAKylaY5hdGKGwa1PTXJG39dhSV6W5MVVdV6SmyZ517RqAAAAAGDtrVhzk3XXWvv7JH8/a/b5Sfae5n4BAAAAWHfTvCQNAAAAgI2QwAgAAACAEYERAAAAACMCIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwIjACAAAAYERgBAAAAMCIwAgAAACAEYERAAAAACMCIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwIjACAAAAYERgBAAAAMCIwAgAAACAEYERAAAAACMCIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwIjACAAAAYERgBAAAAMCIwAgAAACAEYERAAAAACMCIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwIjACAAAAYERgBAAAAMCIwAgAAACAEYERAAAAACMCIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwIjACAAAAYERgBAAAAMCIwAgAAACAEYERAAAAACMCIwAAAABGBEYAAAAAjAiMAAAAABiZamBUVTtW1Ueq6ttVdXZV3aeqblJVn6uqc/vfnaZZAwAAAABrZ9o9jN6c5NOttdsluUuSs5McnOSY1toeSY7p0wAAAAAsE1MLjKrqxkkemORdSdJa+3Vr7cokj01yRG92RJJ9p1UDAAAAAGtvmj2Mbp3k8iT/VlXfqKp3VtWNkuzSWru0t7ksyS5TrAEAAACAtTTNwGhFkrsneXtr7W5JfpFZl5+11lqSNtfKVXVQVZ1cVSdffvnlUywTAAAAgEnTDIwuTnJxa+3EPv2RDAHSD6pq1yTpf38418qttcNaa3u11vZauXLlFMsEAAAAYNLUAqPW2mVJvldVt+2z9knyrSRHJTmwzzswycenVQMAAAAAa2/FlLf/vCRHVtVWSc5P8owMIdWHqupZSS5Ksv+UawAAAABgLUw1MGqtfTPJXnMs2mea+wUAAABg3U1zDCMAAAAANkICIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwIjACAAAAYERgBAAAAMCIwAgAAACAEYERAAAAACMCIwAAAABGBEYAAAAAjCwoMKqq+y1kHgAAAAAbv4X2MHrrAucBAAAAsJFbsbqFVXWfJPdNsrKqXjyxaIckW06zMAAAAACWxmoDoyRbJdmut9t+Yv7Pkuw3raIAAAAAWDqrDYxaa8clOa6qDm+tXbRINQEAAACwhNbUw2jG1lV1WJJVk+u01h4yjaIAAAAAWDoLDYw+nORfkrwzybXTKwcAAACApbbQwOia1trbp1oJAAAAAMvCFgts94mq+rOq2rWqbjJzm2plAAAAACyJhfYwOrD/fenEvJbkDzZsOQAAAAAstQUFRq21W0+7EAAAAACWhwUFRlX1tLnmt9bes2HLAQAAAGCpLfSStHtO3N8myT5JTk0iMAIAAADYxCz0krTnTU5X1Y5JPjCVigAAAABYUgv9lbTZfpHEuEYAAAAAm6CFjmH0iQy/ipYkWya5fZIPTasoAAAAAJbOQscwet3E/WuSXNRau3gK9QAAAACwxBZ0SVpr7bgk306yfZKdkvx6mkUBAAAAsHQWFBhV1f5Jvp7kCUn2T3JiVe03zcIAAAAAWBoLvSTtb5Lcs7X2wySpqpVJPp/kI9MqDAAAAIClsdBfSdtiJizqfrwW6wIAAACwEVloD6NPV9Vnkry/Tz8xyaemUxIAAAAAS2m1gVFV7Z5kl9baS6vq8Unu3xedkOTIaRcHAAAAwOJbUw+jNyX56yRprX00yUeTpKru1Jc9eqrVAQAAALDo1jQO0S6ttTNmz+zzVk2lIgAAAACW1JoCox1Xs+yGG7IQAAAAAJaHNQVGJ1fVc2bPrKpnJzllOiUBAAAAsJTWNIbRC5P8Z1UdkOsDor2SbJXkcdMsDAAAAIClsdrAqLX2gyT3raoHJ7ljn310a+0LU68MAAAAgCWxph5GSZLW2heTfHHKtQAAAACwDKxpDCMAAAAANjMCIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwMvXAqKq2rKpvVNUn+/Stq+rEqjqvqj5YVVtNuwYAAAAAFm4xehi9IMnZE9OvSfLG1truSa5I8qxFqAEAAACABZpqYFRVN0/yyCTv7NOV5CFJPtKbHJFk32nWAAAAAMDamXYPozcl+ask1/Xpmya5srV2TZ++OMluU64BAAAAgLUwtcCoqh6V5IettVPWcf2Dqurkqjr58ssv38DVAQAAADCfafYwul+Sx1TVhUk+kOFStDcn2bGqVvQ2N09yyVwrt9YOa63t1Vrba+XKlVMsEwAAAIBJUwuMWmt/3Vq7eWttVZInJflCa+2AJF9Msl9vdmCSj0+rBgAAAADW3mL8StpsL0vy4qo6L8OYRu9aghoAAAAAmMeKNTdZf621Y5Mc2++fn2TvxdgvAAAAAGtvKXoYAQAAALCMCYwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAICRqQVGVXWLqvpiVX2rqs6qqhf0+Tepqs9V1bn9707TqgEAAACAtTfNHkbXJPnL1tqeSe6d5M+ras8kByc5prW2R5Jj+jQAAAAAy8TUAqPW2qWttVP7/Z8nOTvJbkkem+SI3uyIJPtOqwYAAAAA1t6ijGFUVauS3C3JiUl2aa1d2hddlmSXxagBAAAAgIWZemBUVdsl+Y8kL2yt/WxyWWutJWnzrHdQVZ1cVSdffvnl0y4TAAAAgG6qgVFV3SBDWHRka+2jffYPqmrXvnzXJD+ca93W2mGttb1aa3utXLlymmUCAAAAMGHFtDZcVZXkXUnObq29YWLRUUkOTHJo//vxadUAa2PVwUcvdQmbjAsPfeQG36bjs2E4NsvbNI4PAACsi6kFRknul+SpSc6oqm/2eS/PEBR9qKqeleSiJPtPsQYAAAAA1tLUAqPW2leS1DyL95nWfgEAAABYP4vyK2kAAAAAbDwERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwIjACAAAAIARgREAAAAAIwIjAAAAAEYERgAAAACMCIwAAAAAGBEYAQAAADAiMAIAAABgRGAEAAAAwMiKpS4AAJieVQcfvdQlbBIuPPSRS10CAMCi0sMIAAAAgBGBEQAAAAAjAiMAAAAARgRGAAAAAIwIjAAAAAAY8StpAABLwC/YbTh+xQ4ANjw9jAAAAAAYERgBAAAAMCIwAgAAAGBEYAQAAADAiMAIAAAAgBGBEQAAAAAjAiMAAAAARlYsdQEAALDcrDr46KUuYZNx4aGPXOoSAFgHehgBAAAAMCIwAgAAAGDEJWkAAMBGw+WCG840Lhd0fDacDX18HJsNZ3O51FYPIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwIjACAAAAYERgBAAAAMCIwAgAAACAEYERAAAAACMCIwAAAABGBEYAAAAAjAiMAAAAABgRGAEAAAAwIjACAAAAYERgBAAAAMDIkgRGVfXwqjqnqs6rqoOXogYAAAAA5rbogVFVbZnkn5P8cZI9kzy5qvZc7DoAAAAAmNtS9DDaO8l5rbXzW2u/TvKBJI9dgjoAAAAAmMNSBEa7JfnexPTFfR4AAAAAy0C11hZ3h1X7JXl4a+3ZffqpSe7VWvuLWe0OSnJQn7xtknMWtdDN285JfrTURTAnx2Z5c3yWN8dn+XJsljfHZ/lybJY3x2f5cmyWN8dncd2qtbZyrgUrFruSJJckucXE9M37vJHW2mFJDlusorheVZ3cWttrqevgdzk2y5vjs7w5PsuXY7O8OT7Ll2OzvDk+y5djs7w5PsvHUlySdlKSParq1lW1VZInJTlqCeoAAAAAYA6L3sOotXZNVf1Fks8k2TLJu1trZy12HQAAAADMbSkuSUtr7VNJPrUU+2ZBXAq4fDk2y5vjs7w5PsuXY7O8OT7Ll2OzvDk+y5djs7w5PsvEog96DQAAAMDythRjGAEAAACwjAmMNjJVtaqqzlyP9Q+pqpesZw2fqqod12cbLMzk8aqqw6tqv3XYxqqq+tMNXx2zOTeWh6o6tqrW6Zc1qupBVXXfDV0TLHdr+n5QVftW1Z6LWRMbls+o6XOeLC8z72tV9cqqeuga2j6mqg7u9x3HDayqjl/qGlg3AqPNSFWt15hVNdiitfaI1tqVG6oupm5VEoHRInBubBIelERgBL9r3yT+AbUR8xm1KJwny1Br7e9aa59fQ5ujWmuH9knHcQNrrflutZESGG2ctqyqd1TVWVX12aq6YVXdpqo+XVWnVNWXq+p2yW97pfxLVZ2Y5LV9/btU1QlVdW5VPae3266qjqmqU6vqjKp6bJ+/qqrOqar3JDkzyS2q6sKq2nl2b6ee4B/S7x9bVW+sqpOr6uyqumdVfbTv81WL+FwtS1X1tKo6vapOq6p/78/lF/q8Y6rqlmtY/x5VdVw/3p+pql37/N2r6vN9u6dW1W2SHJrkAVX1zap60WI8vuWsqm5UVUf35+jMqnpif02/tr/2v15Vu/e2K6vqP6rqpH67X5+/XVX9W29/elX9SZ8/eW58u59/36mqI6vqoVX11X4O7D1Ry7v7Pr8xcd49vZ8vn+7tXzvf49mcTTzPR/b3mY9U1baz2ry9vw+dVVWvmJh/YVW9YuI973ZVtSrJc5O8qJ8vD1jcR7Tpmu/zoqqeX1Xf6ufRB/qyOc8LNryq+pv+HvWVJLft857T3+9O6+9/29bQ6+4xSf6pnxu3mavdkj6YTcRifEYt5ePbGFXVx/r3rbOq6qA+76qJ5fv1z/u5zpO7VtXX+nH4z6raqa/je/KUzPO+9tte+lX1iP7d4ZSqektVfbLPf3pVvW2u47hkD2YTMnPO1NCT+7iq+nhVnV9Vh1bVAf297YyZ57uqHl1VJ/bvAZ+vql36/JVV9bl+Pr6zqi7yvjZlrTW3jeiWobfINUnu2qc/lOQpSY5Jskefd68kX+j3D0/yySRb9ulDkpyW5IZJdk7yvSQ3y/CLeTv0NjsnOS9J9f1dl+TeEzVc2NusSnLmxPyXJDmk3z82yWv6/Rck+X6SXZNsneTiJDdd6udyCY/hHZJ8J8nOffomST6R5MA+/cwkH5s4Xi+ZOJb7JblBkuOTrOzzn5jk3f3+iUke1+9vk2TbDD0mPrnUj3u53JL8SZJ3TEzfuL+m/6ZPP23m+UryviT37/dvmeTsfv81Sd40sY2d+t/Jc+OaJHfKEMyfkuTd/Zx67MTxfXWSp/T7O/bXxY2SPD3J+b22bZJclOQWS/3cLbdbf55bkvv16Xf396Fjk+zV592k/92yz7/zxLF6Xr//Z0ne2e//9pxz2+DH6nc+L/pnw9Z93o7975znxVI/hk3tluQeSc7onxM7ZPjcf0kmPp+TvGriPDk8yX4Ty+Zs57bex2Xqn1FL/Rg3ttvE58gNM/zn6U2TXDWxfL8kh/f7s8+T05P8Ub//ypnjEt+Tp3Ws5ntfO7wfp20y/Nvn1r39+yfOp6cnedtcx9Ftgxybq/rfByW5cuL1fkmSV/RlL5g4R3bK9T/Q9ewkr+/335bkr/v9h2f4Huh9bYq39bpEiSVzQWvtm/3+KRm+iN83yYeraqbN1hPtP9xau3Zi+uOttauTXF1VX0yyd5Kjk7y6qh6YISDaLckuvf1FrbWvrUOdR/W/ZyQ5q7V2aZJU1flJbpHkx+uwzU3BQzIckx8lSWvtJ1V1nySP78v/Pdf3BpvLbZPcMcnn+vHeMsmlVbV9kt1aa//Zt/urJJl4TTA4I8nrq+o1Gb4kfLk/R+/vy9+f5I39/kOT7DnxHO5QVdv1+U+amdlau2KO/VzQWjsjSarqrCTHtNZaVZ2R4ZxNkocleUxdP27INhm+9Ke3/2lf/1tJbpXhSw5j32utfbXff2+S589avn//H+EVGb6c7JnhC3ySfLT/PSXXn38srtOTHFlVH0vysT5vvvPi7CWob1P2gCT/2Vr7ZZJU1cxn9h17D4cdk2yX5DPzrL/QdqydxfqMYuGeX1WP6/dvkWSPhaxUVTfOEIQf12cdkeTDE018T97w5ntfm3G7JOe31i7o0+9PctAi1sfgpInX+38n+Wyff0aSB/f7N0/ywRquotgqycwxu3+SxyVJa+3TVeX9bcoERhun/5m4f22GYOfK1tpd52n/i1nTbY7pA5KsTHKP1tpvqurCDF/S51p/xjUZX9a4zazlM3VeN6vm6+K1tz4qwxeL+4xmDoERa9Ba+05V3T3JI5K8qqqOmVk02az/3SJD77pfTW5jgSHc7Nf85Pkw8/qvJH/SWjtn1vbvld89z50zc5vr/SxJUlW3zvA/i/dsrV1RVYdn/E2rXYYAAAa4SURBVD418xx7fqdvvs+LRyZ5YJJHJ/mbqrpT5jkvWDSHJ9m3tXZaVT09w/8Gr0871sIifkaxAFX1oAwB3H1aa7+sqmMzvH9NHo/Z338XyvdkNlcL+Y781iRvaK0d1c/DQxatOkaMYbRp+FmSC6rqCclvB6e+y2raP7aqtqmqm2b4gndShi7PP+xh0YMz9GZYkx8k+b2qumlVbZ3kUev1KDYfX0jyhP78p6pukuESs5n/DTwgyZdXs/45SVb2XkmpqhtU1R1aaz9PcnFV7dvnb13DmBI/TyJM6qrqZkl+2Vp7b5J/SnL3vuiJE39P6Pc/m+R5E+vOhLKfS/LnE/N3WsdyPpPkedW/3VfV3dZxO5uzW86cCxkGd//KxLIdMgTeP+3Xvv/xArbnfJmOuT4vtshwqeUXk7wsw+fQTE8V58X0fSnJvjWMg7h9htAuGV7/l1bVDTJ8Hs2YfW7M1471sMw+oxjel67oYdHtkty7z/9BVd2+qrZI7+3Q/fY86b2Er6jrx8N7apLjwjTN974245wkf1DDmIXJ9efVbL4LLL0bZ7hcLUkOnJj/1ST7J0lVPSzDpWtMkcBo03FAkmdV1WlJzsowTsp8Tk/yxSRfS/IPrbXvJzkyyV79cpmnJfn2mnbYWvtNhuuxv57hy8ka1yFprZ2V5B+THNeP1xsyfOF7RlWdnuELxQtWs/6vM1yH/Zq+/jdz/a86PTVD1+nTM4RQv5/heF9bwwCam/2g1xnGFfp6VX0zyd9nGHsjSXbqz9sLksw8T8/PcF6c3i8Le26f/6re/sx+DB6cdfMPGcakOr1ftvYP67idzdk5Sf68qs7O8KXh7TMLWmunJflGhvem92X4krEmn0jyuDLo9QY1z+fFlkne2z93vpHkLW34BSfnxSJorZ2a5IMZxjX8rwz/eZQk/zfDeHhfzfhz/QNJXlrDAKS3WU071s9y+owi+XSSFf0z5tAM352T5OAMY4Qen+TSifazz5MDMwyefHqSu2Z4H2RKVvO+NrP86gzjFn66qk7JEAz9dI5NzT6OLL5DMgy3ckqSH03Mf0WSh9XwQxpPSHJZhuPIlMwMJAWw2eqXYO41M64UG4f+P4SfbK3dcYlLAZgan1Gw4VTVdq21q3ov1n9Ocm5r7Y1rWo/lofdSvra1dk3vYf721QzLwgbg+lgAAAA2B8+pqgMzDKT8jST/usT1sHZumeRD/XLQXyd5zhLXs8nTwwgAAACAEWMYAQAAADAiMAIAAABgRGAEAAAAwIjACADY5FXVG6vqhRPTn6mqd05Mv76qXryO235QVX1ygW13rKo/W5f9AAAsJoERALA5+GqS+yZJ/3WVnZPcYWL5fZMcv5ANVdWW61HHjkkERgDAsicwAgA2B8cnuU+/f4ckZyb5eVXtVFVbJ7l9klOrap+q+kZVnVFV7+7LUlUXVtVrqurUJE+oqodX1bf79OPn2mFV3aGqvl5V36yq06tqjySHJrlNn/dPvd1Lq+qk3uYVfd6qvv3Dq+o7VXVkVT20qr5aVedW1d7TfLIAAFYsdQEAANPWWvt+VV1TVbfM0JvohCS7ZQiRfprkjAz/kXZ4kn1aa9+pqvck+T9J3tQ38+PW2t2rapsk5yZ5SJLzknxwnt0+N8mbW2tHVtVWSbZMcnCSO7bW7pokVfWwJHsk2TtJJTmqqh6Y5LtJdk/yhCTPTHJSkj9Ncv8kj0ny8iT7bojnBgBgLnoYAQCbi+MzhEUzgdEJE9NfTXLbJBe01r7T2x+R5IET688EQ7fr7c5trbUk751nfyckeXlVvSzJrVprV8/R5mH99o0kp/Zt79GXXdBaO6O1dl2Ss5Ic0/d3RpJVa/PAAQDWlsAIANhczIxjdKcMl6R9LUMPo4WOX/SLtdlZa+19GXoDXZ3kU1X1kDmaVZL/11q7a7/t3lp7V1/2PxPtrpuYvi56iQMAUyYwAgA2F8cneVSSn7TWrm2t/STDINT36cvOSbKqqnbv7Z+a5Lg5tvPt3u42ffrJc+2sqv4gyfmttbck+XiSOyf5eZLtJ5p9Jskzq2q7vs5uVfV76/EYAQA2CP87BQBsLs7I8Oto75s1b7vW2o+SpKqekeTDVbUiw7hB/zJ7I621X1XVQUmOrqpfJvlyxiHQjP2TPLWqfpPksiSvbq39pA9cfWaS/2qtvbSqbp/khKpKkquSPCXJtRvmIQMArJsaLoUHAAAAgIFL0gAAAAAYERgBAAAAMCIwAgAAAGBEYAQAAADAiMAIAAAAgBGBEQAAAAAjAiMAAAAARgRGAAAAAIz8fwpJrOZsnFUMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_7VGmrsum4"
      },
      "source": [
        "## **2. Domain-specific information extraction (10 points)**\n",
        "\n",
        "For the legal case used in the data cleaning exercise: [01-05-1 Adams v Tanner.txt](https://raw.githubusercontent.com/unt-iialab/info5731_spring2021/main/class_exercises/01-05-1%20%20Adams%20v%20Tanner.txt), use [legalNLP](https://lexpredict-lexnlp.readthedocs.io/en/latest/modules/extract/extract.html#nlp-based-extraction-methods) to extract the following inforation from the text (if the information is not exist, just print None):\n",
        "\n",
        "(1) acts, e.g., “section 1 of the Advancing Hope Act, 1986”\n",
        "\n",
        "(2) amounts, e.g., “ten pounds” or “5.8 megawatts”\n",
        "\n",
        "(3) citations, e.g., “10 U.S. 100” or “1998 S. Ct. 1”\n",
        "\n",
        "(4) companies, e.g., “Lexpredict LLC”\n",
        "\n",
        "(5) conditions, e.g., “subject to …” or “unless and until …”\n",
        "\n",
        "(6) constraints, e.g., “no more than”\n",
        "\n",
        "(7) copyright, e.g., “(C) Copyright 2000 Acme”\n",
        "\n",
        "(8) courts, e.g., “Supreme Court of New York”\n",
        "\n",
        "(9) CUSIP, e.g., “392690QT3”\n",
        "\n",
        "(10) dates, e.g., “June 1, 2017” or “2018-01-01”\n",
        "\n",
        "(11) definitions, e.g., “Term shall mean …”\n",
        "\n",
        "(12) distances, e.g., “fifteen miles”\n",
        "\n",
        "(13) durations, e.g., “ten years” or “thirty days”\n",
        "\n",
        "(14) geographic and geopolitical entities, e.g., “New York” or “Norway”\n",
        "\n",
        "(15) money and currency usages, e.g., “$5” or “10 Euro”\n",
        "\n",
        "(16) percents and rates, e.g., “10%” or “50 bps”\n",
        "\n",
        "(17) PII, e.g., “212-212-2121” or “999-999-9999”\n",
        "\n",
        "(18) ratios, e.g.,” 3:1” or “four to three”\n",
        "\n",
        "(19) regulations, e.g., “32 CFR 170”\n",
        "\n",
        "(20) trademarks, e.g., “MyApp (TM)”\n",
        "\n",
        "(21) URLs, e.g., “http://acme.com/”\n",
        "\n",
        "(22) addresses, e.g., “1999 Mount Read Blvd, Rochester, NY, USA, 14615”\n",
        "\n",
        "(23) persons, e.g., “John Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qc7NtJrLx5tS",
        "outputId": "4b839ec3-63bd-4187-90b2-7c252003e2c7"
      },
      "source": [
        "# Install LEXNLP\n",
        "!pip install lexnlp\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lexnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/8f/775b5718bdee8b11bb06a4a49172abec78f9e94b865a7382b3b7d5f69cc5/lexnlp-1.8.0-py3-none-any.whl (9.8MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8MB 6.5MB/s \n",
            "\u001b[?25hCollecting dateparser==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/9d/51126ac615bbc4418478d725a5fa1a0f112059f6f111e4b48cfbe17ef9d0/dateparser-0.7.2-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 44.5MB/s \n",
            "\u001b[?25hCollecting regex==2020.7.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/10/a5f40a296a199dda90432ba0af4dc4221aa5cde31c62b6088c88df971e9e/regex-2020.7.14-cp37-cp37m-manylinux2010_x86_64.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 41.9MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/7e/74e707b66490d4eb05f702966ad0990881127acecf9d5cdcef3c95ec6c16/scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 40.4MB/s \n",
            "\u001b[?25hCollecting joblib==0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/42/155696f85f344c066e17af287359c9786b436b1bf86029bb3411283274f3/joblib-0.14.0-py2.py3-none-any.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 42.4MB/s \n",
            "\u001b[?25hCollecting num2words==0.5.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.4MB/s \n",
            "\u001b[?25hCollecting us==2.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/88/04/04323aefa1871de30286d3decae7706481c73bd428cf0c08e158bfa259a6/us-2.0.2.tar.gz\n",
            "Collecting nltk==3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 43.6MB/s \n",
            "\u001b[?25hCollecting pandas==0.24.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/e6/2d47835f91eb010036be207581fa113fb4e3822ec1b4bafb0d3d105fede6/pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 40.8MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/8f/29d5688614f9bba59931683d5d353d738d4a3007833219ee19c455732753/numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 156kB/s \n",
            "\u001b[?25hCollecting reporters-db==2.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/e9/498bada93e69e3162a027d9285e852c464d66aae23ec3c845700ee117414/reporters_db-2.0.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.0MB/s \n",
            "\u001b[?25hCollecting datefinder-lexpredict==0.6.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/45/d1/e80c60a7c23a4b16338f33345be45c64bd6ff4ef5ab67350b8c94325b8b6/datefinder_lexpredict-0.6.2.1-py2.py3-none-any.whl\n",
            "Collecting scipy==1.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/45/ff9df4beceab76f979ee0ea7f5d248596aa5b0c179aa3d30589a3f4549eb/scipy-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (25.9MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9MB 1.3MB/s \n",
            "\u001b[?25hCollecting pycountry==20.7.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/73/6f1a412f14f68c273feea29a6ea9b9f1e268177d32e0e69ad6790d306312/pycountry-20.7.3.tar.gz (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 45.2MB/s \n",
            "\u001b[?25hCollecting Unidecode==1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 50.0MB/s \n",
            "\u001b[?25hCollecting requests==2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.0MB/s \n",
            "\u001b[?25hCollecting gensim==3.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/afe2315e08a38967f8a3036bbe7e38b428e9b7a90e823a83d0d49df1adf5/gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->lexnlp) (2.8.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->lexnlp) (2018.9)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->lexnlp) (1.5.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words==0.5.10->lexnlp) (0.6.2)\n",
            "Collecting jellyfish==0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/3f/60ac86fb43dfbf976768e80674b5538e535f6eca5aa7806cf2fdfd63550f/jellyfish-0.6.1.tar.gz (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from reporters-db==2.0.3->lexnlp) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2.10)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->lexnlp) (4.2.0)\n",
            "Building wheels for collected packages: us, nltk, pycountry, jellyfish\n",
            "  Building wheel for us (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for us: filename=us-2.0.2-cp37-none-any.whl size=11929 sha256=5c5dc1eda7ef4a75fcb1147267b78d2a1cc8b8422487fb580689f5df0b9db880\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/16/45/6453383ffa495670f0f6b80a3e697a9771d98cfbaf8b451e73\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp37-none-any.whl size=1434675 sha256=d206a31be45336f5c39cc67e245fb87d6226f617e7d0153b88ee874f54aa3e0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746863 sha256=0866bc9786d39f0d4a8f1b4b08834276884064972d0ad0e089727d5e3cb38360\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/4e/a6/be297e6b83567e537bed9df4a93f8590ec01c1acfbcd405348\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.6.1-cp37-cp37m-linux_x86_64.whl size=72183 sha256=7eeb418cc3930f252565982617914ddcdc40b6f8534b002b6d586ffed46b0971\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/6f/33/92bb9a4b4562a60ba6a80cedbab8907e48bc7a8b1f369ea0ae\n",
            "Successfully built us nltk pycountry jellyfish\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: regex, dateparser, joblib, numpy, scipy, threadpoolctl, scikit-learn, num2words, jellyfish, us, nltk, pandas, reporters-db, datefinder-lexpredict, pycountry, Unidecode, requests, gensim, lexnlp\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed Unidecode-1.1.1 datefinder-lexpredict-0.6.2.1 dateparser-0.7.2 gensim-3.8.3 jellyfish-0.6.1 joblib-0.14.0 lexnlp-1.8.0 nltk-3.5 num2words-0.5.10 numpy-1.19.1 pandas-0.24.2 pycountry-20.7.3 regex-2020.7.14 reporters-db-2.0.3 requests-2.24.0 scikit-learn-0.23.1 scipy-1.5.1 threadpoolctl-2.1.0 us-2.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6lDwQI7YeWQ"
      },
      "source": [
        "# Read text data\n",
        "with open('01-05-1 Adams v Tanner.txt') as f:\n",
        "    text = f.read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Het8gf_kZ-s4",
        "outputId": "3e73525e-5617-4800-82ba-ba7bc85b6de5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nfVFNYyWcH9",
        "outputId": "bf9e1a20-582b-4287-c75c-e84dd045cd16"
      },
      "source": [
        "import lexnlp.extract.en.acts\n",
        "import lexnlp.extract.en.amounts\n",
        "import lexnlp.extract.en.citations\n",
        "import lexnlp.extract.en.entities.nltk_re\n",
        "import lexnlp.extract.en.conditions\n",
        "import lexnlp.extract.en.constraints\n",
        "import lexnlp.extract.en.copyright\n",
        "import lexnlp.extract.en.courts\n",
        "import lexnlp.extract.en.cusip\n",
        "import lexnlp.extract.en.dates\n",
        "import lexnlp.extract.en.definitions\n",
        "import lexnlp.extract.en.distances\n",
        "import lexnlp.extract.en.durations\n",
        "import lexnlp.extract.en.money\n",
        "import lexnlp.extract.en.percents\n",
        "import lexnlp.extract.en.pii\n",
        "import lexnlp.extract.en.ratios\n",
        "import lexnlp.extract.en.regulations\n",
        "import lexnlp.extract.en.trademarks\n",
        "import lexnlp.extract.en.urls\n",
        "\n",
        "print(lexnlp.extract.en.acts.get_act_list(text))\n",
        "print(list(lexnlp.extract.en.citations.get_citations(text)))\n",
        "print(list(lexnlp.extract.en.entities.nltk_re.get_companies(text)))\n",
        "print(list(lexnlp.extract.en.conditions.get_conditions(text)))\n",
        "print(list(lexnlp.extract.en.constraints.get_constraints(text)))\n",
        "print(list(lexnlp.extract.en.copyright.get_copyright(text)))\n",
        "print(list(lexnlp.extract.en.cusip.get_cusip(text)))\n",
        "print(list(lexnlp.extract.en.dates.get_dates(text)))\n",
        "print(list(lexnlp.extract.en.definitions.get_definitions(text)))\n",
        "print(list(lexnlp.extract.en.distances.get_distances(text)))\n",
        "print(list(lexnlp.extract.en.durations.get_durations(text)))\n",
        "print(list(lexnlp.extract.en.money.get_money(text)))\n",
        "print(list(lexnlp.extract.en.percents.get_percents(text)))\n",
        "print(list(lexnlp.extract.en.pii.get_pii(text)))\n",
        "print(list(lexnlp.extract.en.ratios.get_ratios(text)))\n",
        "print(list(lexnlp.extract.en.regulations.get_regulations(text)))\n",
        "print(list(lexnlp.extract.en.trademarks.get_trademarks(text)))\n",
        "print(list(lexnlp.extract.en.urls.get_urls(text)))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[(5, 'Ala.', 'Alabama Reports', 740, None, None, None), (5, 'Ala.', 'Alabama Reports', 740, '1843', None, None), (55, 'Ala.', 'Alabama Reports', 266, '271', None, None), (47, 'Ala.', 'Alabama Reports', 362, '376', None, None), (45, 'Ala.', 'Alabama Reports', 329, '334', None, None), (31, 'Ala.', 'Alabama Reports', 526, '527', None, None), (21, 'Ala.', 'Alabama Reports', 333, '335', None, None), (8, 'Cal.', 'California Reports', 145, '147', None, None), (65, 'Ala.', 'Alabama Reports', 256, '258', None, None), (4, 'S.W.', 'South Western Reporter', 913, '914', None, None), (103, 'A.L.R.', 'American Law Reports', 464, None, None, None), (9, 'Cow.', \"Cowen's Reports\", 39, None, None, None), (5, 'Port.', 'Alabama Reports, Porter', 182, None, None, None), (9, 'Johns.', \"Johnson's Reports\", 108, None, None, None)]\n",
            "[Lehman, Durr Co, (17983, 18001)]\n",
            "[('until', '[2]\\nCreditors’ Remedies\\nLien and Priority\\nUnder St.1821, prohibiting a levy on a crop', ''), ('until', 'on a growing crop, nor does such lien attach', ''), ('if', 'It was proved by the claimants, by the production of a written contract, that Harrison, on the twenty-second of May, 1840, in consideration that the claimants were involved, as indorsers for Burton & Harrison of Sumter county, and were then exposed to an execution, amounting to upwards of fourteen thousand dollars, bargained and sold to the claimants all his growing crop of cotton &c., consisting of one hundred and twenty acres, &c. Allen Harrison promised and obliged himself to give up his crop to the use of the claimants at any time to save them from suffering as his indorsers;', ''), ('when', 'The claimants came from Tennessee, (where they resided) about the first of September, 1840, bringing with them three or four white laborers, and took possession of the crop and slaves, and with the latter, and white laborers, gathered the cotton, prepared it for market, and', ''), ('if', 'The court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that Harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but', ''), ('when', 'it was not, and the lien of the fieri facias would have attached upon it,', ''), ('if', 'gathered, yet', ''), ('not subject to', 'the claimants obtained possession on the first of September, and controlled the gathering of the crop, then no lien attached, and it was', ''), ('until', 'Rep, 693;] and', ''), ('until', '167,] which declares it to be lawful to levy an execution on a planted crop,', ''), ('if', 'It is admitted that the contract between the defendant in execution, and the claimants, was in good faith,', ''), ('when', 'The defendant in execution might at any time have divested the interest which the contract vested in the claimants, by discharging their liability as his indorsers, or a judgment creditor might have satisfied the lien, and', ''), ('unless', 'We will then consider the writing under which the claimants assert a right, as a mortgage with a power to take possession any time during the year,', ''), ('if', 'Conceding the truth of the facts stated in the bill of exceptions, and we think it will not follow, that the possession of the claimants is a nullity, and that the case must be considered as', ''), ('if', 'The contract contains an express undertaking to give up the crop at any time the claimants might require it for their indemnity, and', ''), ('if', 'they took possession of it in the absence of the grantor, (though without his consent,)', ''), ('if', 'he subsequently acquiesced in it, the inference would be,', ''), ('subject to', 'Mr. Dane, in remarking upon this point, says, “The American editor of Bacon’s Abridgment, says, ‘Wheat growing in the ground is a chattel, and', ''), ('until', 'The first section of the act of 1821, “To prevent sheriffs and other officers from levying executions in certain cases, enacts, that “It shall not be lawful for any sheriff or other officer, to levy a writ of fieri facias or other execution on the planted crop of a debtor, or person against whom an execution may issue,', ''), ('until', 'Now here is an express inhibition to levy an execution on a crop while it remains on, or in the ground, and', ''), ('until', 'If so, the act cited, will only have the effect of keeping the right to levy it in abeyance', ''), ('if', 'The lien and the right to levy are intimately connected, and', ''), ('until', 'That it was competent for the legislature to have made it unlawful to levy an execution on particular property,', ''), ('until', 'If the object was merely to suspend the sale,', ''), ('as soon as', 'The idea that the lien attached upon the planted crop', ''), ('until', 'the execution was delivered to the sheriff, though the right to levy it was postponed', ''), ('if', 'They do not refer to the lien,', ''), ('until', 'they did they would postpone it', ''), ('until', 'the crop was gathered; but it is the levy they relate to and postpone', ''), ('until', '**4 The right to levy an execution on a planted crop, then, being expressly taken away by the statute, the lien which is connected with and consequent upon that right, never attaches', ''), ('if', 'The circuit judge may have mistaken the law in supposing that the contract was a sale, but', ''), ('when', 'There is no assumption of any material fact in the charge; but the possession of the claimant, the time', ''), ('if', 'acquired, the gathering of the crop, &c., are all referred to the determination of the jury; who are instructed,', ''), ('until', '**4 The statute which presents the question before the court is, that “it shall not be lawful for any sheriff or other officer to levy a writ of fieei facias or other execution, on the planted crop of a debtor, or person against whom an execution may issue,', ''), ('subject to', 'The policy of the State, as indicated by these statutes, is undeniably that all the property of a debtor, real and personal, to which he has a legal title, shall be', ''), ('until', 'The mischief which the statute designed to remedy was, the sacrifice which would be necessarily made by the sale of an immature crop: the statute enables the debtor to retain it', ''), ('if', '**5', ''), ('until', 'The sheriff is forbidden to levy on a “planted crop”', ''), ('if', 'Now,', ''), ('until', 'This, I feel a thorough conviction, was not the intention of the legislature; but that it was to secure him from loss, by prohibiting a levy and sale of the crop,', ''), ('when', 'it was gathered,', ''), ('subject to', 'Growing crops as', ''), ('subject to', '464\\nGenerally, at common law, growing crops raised by annual planting, while still attached to the soil, are regarded as personal chattels,', ''), ('where', 'And', '')]\n",
            "[('after', 'on a growing crop, nor does such lien attach until', ''), ('after', '', ' and that alias and pluries fieri facias’, issued regularly up to the time levy was made; that the cotton levied on was growed on the plantation of harrison, and cultivated by the hands in his service.'), ('first of', 'the claimants came from tennessee, (where they resided) about the', ''), ('first of', 'the court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but if it was not, and the lien of the fieri facias would have attached upon it, when gathered, yet if the claimants obtained possession on the', ''), ('after', 'it merely inhibits the levy, but the lien attaches, and a levy and sale may be made', ''), ('more than', 'taking this to be clear *744 law, and it will be seen, that the defendant in execution at the time of the levy had nothing', ''), ('before', 'it has been frequently mooted whether, at common law, corn, &c.,', ''), ('before', '**4 the statute which presents the question', ''), ('after', 'now, if the view taken by the majority of the court, is correct, the right secured to the plaintiff in execution, of levying on the crop', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', '')]\n",
            "[('©', '2019', 'Thomson Reuters. No')]\n",
            "[]\n",
            "[datetime.date(2021, 6, 1), datetime.date(1840, 11, 1), datetime.date(1839, 10, 1), datetime.date(1840, 9, 1), datetime.date(1840, 5, 1), datetime.date(1840, 5, 1), datetime.date(2021, 12, 1), datetime.date(2021, 12, 1), datetime.date(2021, 1, 1), datetime.date(2021, 1, 1), datetime.date(2021, 1, 1), datetime.date(2021, 3, 21), datetime.date(2021, 6, 1), datetime.date(2021, 7, 1), datetime.date(2021, 11, 1)]\n",
            "[]\n",
            "[]\n",
            "[('second', Decimal('20.0'), Decimal('0.0002')), ('year', Decimal('6.0'), Decimal('2190.0'))]\n",
            "[(Decimal('100.0'), 'USD'), (Decimal('14000.0'), 'USD'), (Decimal('14000.0'), 'USD')]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hi3O5qkoTt5",
        "outputId": "6b4d59df-07e7-446e-9c46-81e16a4ff248"
      },
      "source": [
        "# LEXNLP NLP methods\n",
        "import lexnlp.nlp.en.tokens\n",
        "import lexnlp.extract.en.addresses.addresses\n",
        "\n",
        "#lexnlp.nlp.en.tokens.get\n",
        "# Note - LexNLP methods for person name extraction not implmented or not documented\n",
        "# Substituting noun extraction\n",
        "print(list(lexnlp.nlp.en.tokens.get_nouns(text)))\n",
        "print(list(lexnlp.extract.en.addresses.addresses.get_addresses(text)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ala.', 'Supreme', 'Court', 'Alabama.', 'ADAMS', 'v.', 'TANNER', 'AND', 'HORTON.', 'June', 'Term', 'Synopsis', 'WRIT', 'Error', 'Circuit', 'Court', 'Sumter.', 'West', 'Headnotes', 'Chattel', 'Mortgages', 'Crops', 'A', 'crop', 'existence', 'subject-matter', 'mortgage', 'contract', 'interest', 'possession', 'future', 'time.', 'Cases', 'headnote', 'Creditors', 'Remedies', 'Lien', 'Priority', 'St.1821', 'levy', 'crop', 'lien', 'attaches', 'favor', 'fa.', 'crop', 'attach', 'crop', 'Cases', 'headnote', '*', 'trial', 'right', 'property', 'statute.', 'November', 'execution', 'circuit', 'court', 'Sumter', 'suit', 'plaintiff', 'error', 'sheriff', 'county', 'goods', 'c.', 'Allen', 'Harrison', 'others', 'sum', 'dollars', 'costs.', 'execution', 'thirty', 'bales', 'cotton', 'property', 'Allen', 'Harrison', 'bond', 'right.', 'issue', 'question', 'liability', 'cotton', 'plaintiff', '’', 's', 'execution', 'jury.', 'trial', 'bill', 'exceptions', 'instance', 'plaintiff.', 'plaintiff', 'judgment', 'October', 'execution', 'thereon', 'Nov.', 'alias', 'pluries', '’', 'time', 'levy', 'cotton', 'plantation', 'Harrison', 'hands', 'service.', 'claimants', 'production', 'contract', 'Harrison', 'twenty-second', 'May', 'consideration', 'claimants', 'indorsers', 'Burton', 'Harrison', 'Sumter', 'county', 'execution', 'upwards', 'dollars', 'claimants', 'crop', 'cotton', 'c.', 'acres', 'c.', 'Allen', 'Harrison', 'crop', 'use', 'claimants', 'time', 'indorsers', 'crop', 'cotton', 'Gainesville.', 'claimants', 'Tennessee', 'September', 'laborers', 'possession', 'crop', 'slaves', 'latter', 'laborers', 'cotton', 'market', 'ware-house', 'Gainesville.', 'plaintiff', 'Harrison', 'claimants', 'possession', 'crop', 'consent.', 'contract', 'faith.', 'court', 'jury', 'plaintiff', 'lien', 'virtue', 'judgment', 'execution', 'crop', 'Harrison', 'right', 'manner', 'writing', 'sale', 'crop', 'lien', 'fieri', 'facias', 'claimants', 'possession', 'September', 'gathering', 'crop', 'lien', 'levy.', 'Attorneys', 'Law', 'Firms', 'R.', 'H.', 'SMITH', 'plaintiff', 'error', 'points.', 'crop', 'Harrison', 'May', 'immature', 'state', 'subject', 'sale.', 'law', 'crop', 'Salk.', 'Rep.', 'Bos.', 'P.', 'Rep.', 'East', '’', 'Rep.', 'note', 'Johns.', 'Rep.', 'Mass.', 'Rep.', ']', 'statue', '[', '[', '[', 'Aik.', 'Dig.', '§', 'p.', 'levy', 'execution', 'crop', 'construction.', 'levy', 'lien', 'attaches', 'levy', 'sale', 'crop', 'contract', 'crop', 'executory', 'agreement', 'act', 'Harrison', 'order', 'claimants', 'right', '[', 'Chit.', 'Con.', 'Johns.', 'Rep.', 'Wend.', 'Rep.', 'Johns.', 'Rep.', 'Dowl.', 'Rep', ']', 'act', 'crop', 'matter', 'Harrison', '’', 'A', 'court', 'chancery', 'performance', 'contract', 'claimant', '’', 'charge', 'court', 'W.', 'M.', 'MURPHY', 'W.', 'G.', 'JONES', 'defendant', 'act', '[', 'Aik.', 'Dig.', 'execution', 'crop', 'lien', 'favor', 'plaintiff.', 'case', 'defendant', 'execution', 'contract', 'claimants.', '*', 'lien', 'execution', 'injunction', 'right', 'it.', 'right', 'execution', 'withdrawn', 'lien', 'time', '[', '[', '[', 'Whipple', 'Foot', 'Johns.', 'Rep.', 'Wash.', 'C.', 'C.', 'Rep.', 'How.', 'Rep.', ']', 'contract', 'defendant', 'execution', 'claimants', 'faith', 'severance', 'removal', 'cotton', 'latter', 'title', 'creditors', 'Opinion', 'COLLIER', 'C.', 'J.', 'doubt', 'crop', 'existence', 'matter', 'sale', 'mortgage', 'contract', 'interest', 'possession', 'future', 'proposition', 'point', 'inquiry', 'statute', 'frauds', 'Chas.', 'chattel', 'parol', '[', 'Chitty', 'Con.', 'Whipple', 'Foot', 'Johns.', 'Rep.', 'Stewart', 'Doughty', 'Johns.', 'Rep.', 'Austin', 'v.', 'Sawyer', 'Cow.', 'Rep.', 'See', 'v.', 'Lee', 'Alston', 'term.', 'contract', 'bill', 'exceptions', 'evidences', 'mortgage', 'sale.', 'claimants', 'indorsers', 'firm', 'defendant', 'partner', 'execution', 'upwards', 'dollars', 'estate', 'sheriff', '’', 's', 'hands', 'conveyance', 'crop', 'cotton', 'corn', 'oats', 'grantor', 'time', 'use', 'claimants', 'injury', 'indorsers.', 'defendant', 'execution', 'time', 'interest', 'contract', 'claimants', 'liability', 'indorsers', 'judgment', 'creditor', 'lien', 'crop', 'facias.', 'writing', 'claimants', 'right', 'mortgage', 'power', 'possession', 'time', 'year', 'engagements', 'indorsers.', 'liability', 'parties', 'faith', 'question', 'law', 'right', 'plaintiff', 'claimants', 'Assuming', 'execution', 'plaintiffs', 'lien', 'crop', 'contract', 'May', 'defendant', 'execution', 'interest', 'claimants', 'levy', 'execution', 'possession', 'crop', 'cotton', 'market', 'ware-house.', 'possession', 'trespass', 'absence', 'defendant', 'execution', 'consent', 'truth', 'facts', 'bill', 'exceptions', 'possession', 'claimants', 'nullity', 'case', 'crop.', 'contract', 'express', 'undertaking', 'crop', 'time', 'claimants', 'indemnity', 'possession', 'absence', 'grantor', 'consent', 'inference', 'acts', 'him.', '*', 'law', 'defendant', 'execution', 'time', 'levy', 'nothing', 'right', 'cotton', 'debts', 'claimants.', 'possession', 'equity', 'equity', 'execution.', '[', 'Perkins', 'Elliott', 'v.', 'Mayfield', 'Porter', '’', 'Rep.', ']', '*', 'question', 'execution', 'plaintiff', 'lien', 'crop', 'mortgage', 'claimants.', 'law', 'corn', 'c.', 'fieri', 'facias.', 'Mr.', 'Dane', 'point', 'editor', 'Bacon', '’', 'Abridgment', 'Wheat', 'ground', 'chattel', 'execution', 'sheriff', 'till', 'harvest', 'purchaser', 'purpose', '[', 'Foot', 'supra', 'Poole', '’', 's', 'case', 'Salk.', 'Bos.', 'P.', 'East', ']', 'Whipple', 'Foot', 'case', 'position', 'wheat', 'corn', 'execution', 'editor', 'states', 'nothing', 'execution', 'position', 'commentator', 'doubt', 'matter', 'law.', 'section', 'act', 'sheriffs', 'officers', 'executions', 'cases', 'enacts', 'sheriff', 'officer', 'writ', 'facias', 'execution', 'crop', 'debtor', 'person', 'execution', 'crop', '”', '[', 'Aik.', 'Dig.', ']', 'inhibition', 'execution', 'crop', 'ground', 'soil', 'growth.', 'respect', 'property', 'lien', 'execution', 'attach', 'instanti', 'hands', 'officer', 'act', 'effect', 'right', 'abeyance', 'crop', 'lien', 'execution', 'debtor', 'property', 'creditor', 'right', '*', 'judgment.', 'lien', 'right', 'latter', 'effect', 'law', 'destruction', 'former.', 'principle', 'Mansony', 'Hurtell', 'President', 'c.', 'Bank', 'United', 'States', 'assignees', 'citations', 'opinion', 'court', 'case', 'opinion', 'Wood', 'v.', 'Gary', 'et', 'al.', 'term.', 'competent', 'legislature', 'execution', 'property', 'condition', 'lien', 'nothing', 'act', 'question', 'intention.', 'object', 'sale', 'crop', 'explicit', 'terms', 'statute', 'verbis', 'execution', 'legislature', 'act', 'doubts', 'law', 'doubts', 'law', 'lien', 'levy', 'case', 'law', 'idea', 'lien', 'crop', 'execution', 'sheriff', 'right', 'severance', 'place', 'words', 'section', 'viz', '“', 'crop', 'words', 'principles', 'construction', 'execution', 'effect.', 'lien', 'crop', 'levy', 'event', '*', '*', 'right', 'execution', 'crop', 'statute', 'lien', 'right', 'severance.', 'case', 'right', 'defendant', 'execution', 'contract', 'title', 'claimants', 'possession', 'paramount', 'lien', 'execution', 'circuit', 'judge', 'law', 'contract', 'sale', 'error', 'respect', 'sale', 'mortgage', 'facts', 'case', 'defendant', 'execution', 'interest', 'execution.', 'assumption', 'fact', 'charge', 'possession', 'claimant', 'time', 'gathering', 'crop', 'c.', 'determination', 'jury', 'evidence', 'lien', 'favor', 'plaintiff.', 'bona', 'fides', 'contract', 'charge', 'point', 'propriety', 'enter', 'inquiry', 'jury.', 'results', 'judgment', 'circuit', 'court', 'DISSENTING', 'OPINION.', 'ORMOND', 'J.', '*', 'statute', 'question', 'court', 'sheriff', 'officer', 'writ', 'facias', 'execution', 'crop', 'debtor', 'person', 'execution', 'crop', '”', '[', 'Clay', '’', 'Dig.', ']', 'enquiry', 'law', 'execution', 'crop', 'affirmative', 'proposition.', 'purpose', 'statute', 'supposes', 'law', 'doubtless', 'practice.', 'act', 'connection', 'acts', 'policy', 'State', 'statutes', 'property', 'debtor', 'title', 'sale', 'execution', 'reason', 'exemption', 'species', 'property', 'claims', 'creditors', 'defendant', 'execution', 'right', 'it.', 'deference', 'argument', 'sheriff', '“', 'crop', 'execution', 'lien', 'debtor', 'right', 'sequitur.', 'mischief', 'statute', 'sacrifice', 'sale', 'immature', 'crop', 'statute', 'debtor', 'soil', 'condition', 'value', 'lien', 'time', 'plaintiff', '*', 'confirmation', 'correctness', 'view', 'language', 'legislature.', 'sheriff', '“', 'crop', '”', 'crop', 'view', 'majority', 'court', 'right', 'plaintiff', 'execution', 'crop', 'case', 'sale', 'defendant', 'execution', 'crop', 'immature', 'construction', 'statute', 'anomaly', 'legislature', 'protection', 'debtor', 'plaintiff', 'execution', 'property', 'debtor', 'condition', 'value', 'debtor', 'sale', 'sacrifice', 'benefit.', 'effect', 'gift', 'defendant', 'execution', 'crop', 'disposes', 'condition.', 'conviction', 'intention', 'legislature', 'loss', 'levy', 'sale', 'crop', 'suspension', 'right', 'Citations', 'Ala.', 'WL', 'End', 'Document', '©', 'Thomson', 'Reuters.', 'No', 'claim', 'U.S.', 'Government', 'Works.', 'Citing', 'References', 'Treatment', 'Title', 'Date', 'Type', 'Depth', 'Headnote', 's', 'Booker', 'v.', 'Jones', '’', 'Adm', '’', 'x', 'Ala.', 'Ala.', 'Trover', 'Conversion', 'Cotton', 'Counts', 'Case.', 'APPEAL', 'Circuit', 'Court', 'Hale.', 'Tried', 'Hon.', 'M.', 'J.', 'SAFFOLD.', 'Dec', 'Term', 'Case', '—', 'Cited', 'Lehman', 'Durr', 'Co.', 'Marshall', 'Ala.', 'Ala.', '[', 'TROVER', 'FOR', 'CONVERSION', 'OF', 'COTTON.', ']', 'APPEAL', 'City', 'Court', 'Montgomery.', 'Tried', 'Hon.', 'JOHN', 'D.', 'CUNNINGHAM.', 'Jan', 'Term', 'Case', '—', 'Cited', 'Bibb', 'v.', 'Janney', 'Ala.', 'Ala.', '[', 'GARNISHMENT', 'WAGES', 'WAIVER', 'OF', 'EXEMPTION.', ']', 'APPEAL', 'City', 'Court', 'Montgomery.', 'Tried', 'Hon.', 'JOHN', 'D.', 'CUNNINGHAM.', 'Jan', 'Term', 'Case', '—', 'Cited', 'McKenzie', 'v.', 'Lampley', 'Ala.', 'Ala.', '[', 'TRIAL', 'OF', 'RIGHT', 'OF', 'PROPERTY', 'IN', 'COTTON.', ']', 'APPEAL', 'Circuit', 'Court', 'Barbour.', 'Tried', 'Hon.', 'S.', 'D.', 'HALE.', 'Jan', 'Term', 'Case', '—', 'Cited', 'Evans', 'Lamar', 'Ala.', 'Ala.', 'ERROR', 'Circuit', 'Court', 'Autauga.', 'Tried', 'Hon.', 'A.', 'B.', 'MOORE.', 'Jun', 'Term', 'Case', '—', 'Cited', 'Dewey', 'v.', 'Bowman', 'Cal.', 'Cal.', 'judgment', 'Court', 'Jacob', 'S.', 'Cohen', 'reasons', 'finding', 'Court', 'Cohen', 'Jul', 'Term', 'Case', '—', 'Rees', 'Coats', 'Ala.', 'Ala.', 'Trover', 'Conversion', 'Three', 'Bales', 'Cotton.', 'APPEAL', 'Circuit', 'Court', 'Etowah.', 'Tried', 'Hon.', 'WM.', 'L.', 'WHITLOCK.', 'Nov', 'Term', 'Case', '—', 'Edwards', 'Thompson', 'S.W.', 'Tenn.', 'Appeal', 'circuit', 'court', 'Weakley', 'county.', 'May', 'Case', '—', 'crops', 'subject', 'attachment', 'execution', 'A.L.R.', 'Generally', 'law', 'crops', 'planting', 'soil', 'chattels', 'attachment', 'ALR', '—', '—', 'Table', 'Authorities', 'Treatment', 'Referenced', 'Title', 'Type', 'Depth', 'Quoted', 'Page', 'Number', 'Austin', 'v.', 'Sawyer', 'Cow.', 'N.Y.Sup.', 'Parol', 'evidence', 'contract.', 'A.', 'land', 'W.', 'crop', 'wheat', 'Case', 'Perkins', 'Mayfield', 'Port.', 'Ala.', 'writ', 'error', 'Circuit', 'Court', 'Tuskaloosa.', 'Case', 'Stewart', 'v.', 'Doughty', 'Johns.', 'N.Y.Sup.', 'A.', 'B.', 'farm', 'years', 'A.', '“', 'yield', 'pay', 'half', 'wheat', 'rye', 'corn', 'grain', 'farm', 'year', 'Case', 'Filings', 'Filings', 'Negative', 'Treatment', 'Negative', 'Treatment', 'results', 'History', 'History', 'results', 'citation']\n",
            "['TANNER AND HORTON. June Term, 1843. Synopsis', '207; 3 Johns. Rep. 338', '2 Johns. Rep. 216; 3', 'Opinion COLLIER, C. J', 'DISSENTING OPINION. ORMOND, J', '2019 Thomson Reuters', 'TROVER FOR CONVERSION OF', 'Hon. A. B. MOORE. Jun', 'Hon. WM. L. WHITLOCK. Nov', '103 A.L.R. 464 Generally', '9 Johns. 108, N.Y.Sup., 1812']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv_FbIDfWVtM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}